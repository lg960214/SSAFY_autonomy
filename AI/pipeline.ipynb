{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4acec227-a776-423a-bc7d-e355e1fd5ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.components import create_component_from_func, InputPath, OutputPath\n",
    "from kubernetes import client as k8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3421a41-6b69-472a-b148-c0e3c7428034",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2e581d9-3712-42ea-afbc-5e228c27efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_IMAGE = \"python:3.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11def3a7-2e62-4a96-9881-908d07449a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(\n",
    "    output_dataframe_path: OutputPath()\n",
    "):\n",
    "    import pandas as pd\n",
    "    import influxdb_client\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    bucket = \"MaiL\"\n",
    "    config_path = \"/mnt/data/config.ini\"\n",
    "    \n",
    "    retDf = pd.DataFrame()\n",
    "    colName = []\n",
    "    client = influxdb_client.InfluxDBClient.from_config_file(config_path)\n",
    "    query_api = client.query_api()\n",
    "    query = f'from(bucket:\"{bucket}\")\\\n",
    "    |> range(start:-1d)\\\n",
    "    |> filter(fn:(r)=> r._measurement==\"SensorData\" and r.Name==\"M16M\")'\n",
    "\n",
    "    result = query_api.query(query=query)\n",
    "\n",
    "    for table in result:\n",
    "        col = table.records[0].get_field()\n",
    "        colName.append(col)\n",
    "        temp = []\n",
    "        for record in table.records:\n",
    "            temp.append((int(record.get_value())))\n",
    "        retDf[col] = temp\n",
    "    \n",
    "    retDf = retDf[[\"MM\", \"DD\", \"Day\", \"HH\", \"Min\", \"Sec\",\n",
    "    \"Illuminance\", \"Movement\", \"Manual\", \"On\",\n",
    "     \"Brightness\"]]\n",
    "    output_path = Path(output_dataframe_path)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    retDf.to_csv(output_path/\"data.csv\", mode='w',index = False)\n",
    "    # return retDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecdb749c-6ec5-4051-ab2b-b862ade3676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "getData_op = create_component_from_func(getData,\n",
    "                                        base_image=BASE_IMAGE,\n",
    "                                        packages_to_install=[\"pandas\",\"influxdb_client\",\n",
    "                                                            \"pathlib\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "493aaef9-34de-4981-a70b-634ec74fd08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataSplit(\n",
    "    dataframe_path : InputPath(),\n",
    "    output_dataframe_path: OutputPath()\n",
    "             ):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from pathlib import Path\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    input_path = Path(dataframe_path)\n",
    "    output_path = Path(output_dataframe_path)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    myData = np.genfromtxt(input_path/\"data.csv\", delimiter=\",\", dtype = int)\n",
    "    feature_size = myData.shape[1] - 1\n",
    "    x_train, x_test, y_train, y_test = train_test_split(myData[:,:feature_size], myData[:,feature_size:],\n",
    "                                                    test_size=0.1, random_state=42,\n",
    "                                                   shuffle=False)\n",
    "    \n",
    "    np.savetxt(output_path/\"x_train.csv\",x_train, delimiter=\",\", fmt=\"%d\")\n",
    "    np.savetxt(output_path/\"x_test.csv\",x_test, delimiter=\",\", fmt=\"%d\")\n",
    "    np.savetxt(output_path/\"y_train.csv\",y_train, delimiter=\",\", fmt=\"%d\")\n",
    "    np.savetxt(output_path/\"y_test.csv\",y_test, delimiter=\",\", fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe56b3d9-4a5a-4714-903a-29534889176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSplit_op = create_component_from_func(dataSplit,\n",
    "                                        base_image=BASE_IMAGE,\n",
    "                                        packages_to_install=[\"numpy\",\"pandas\", \"pathlib\",\n",
    "                                                            \"scikit-learn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9aec8b2-d9b8-409c-8f5b-d7202f60e704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelTransferLearning(\n",
    "    dataframe_path : InputPath(),\n",
    "    # x_train, y_train,\n",
    "    # pre_model\n",
    "    output_model_path : OutputPath()\n",
    "):\n",
    "    import tensorflow as tf\n",
    "    import matplotlib.pyplot as plt\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    dataframe_path = Path(dataframe_path)\n",
    "    output_path = Path(output_model_path)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    x_train = np.genfromtxt(dataframe_path/\"x_train.csv\", delimiter=\",\", dtype=int)\n",
    "    y_train = np.genfromtxt(dataframe_path/\"y_train.csv\", delimiter=\",\", dtype=int)\n",
    "    \n",
    "    x_test = np.genfromtxt(dataframe_path/\"x_test.csv\", delimiter=\",\", dtype=int)\n",
    "    y_test = np.genfromtxt(dataframe_path/\"y_test.csv\", delimiter=\",\", dtype=int)\n",
    "    \n",
    "    model_path = \"/mnt/data/myModel\"\n",
    "    pre_model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    pre_feat = pre_model.layers[0].input.shape[1]\n",
    "    new_feat = x_train[1].shape[0]\n",
    "    feat_change = False\n",
    "    \n",
    "    if pre_feat == new_feat:\n",
    "        model.add(pre_model.layers[0])\n",
    "    else:\n",
    "        model.add(tf.keras.layers.Dense(16, activation = 'relu', input_shape = (new_feat, )))\n",
    "        feat_change = True\n",
    "    \n",
    "    for i in range(1, len(pre_model.layers)):\n",
    "        model.add(pre_model.layers[i])\n",
    "    for i in range(len(pre_model.layers) - 2):\n",
    "        if feat_change and i == 0: continue\n",
    "        model.layers[i].trainable = False\n",
    "    \n",
    "    model.compile(optimizer = 'adam', loss = 'mse')\n",
    "    history = model.fit(x_train, y_train,\n",
    "    epochs = 10,\n",
    "    batch_size = 32,\n",
    "    validation_split = 0.18)\n",
    "\n",
    "    # Visualization\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    model.save(output_path/\"myModel\")\n",
    "    np.savetxt(output_path/\"x_test.csv\",x_test, delimiter=\",\", fmt=\"%d\")\n",
    "    np.savetxt(output_path/\"y_test.csv\",y_test, delimiter=\",\", fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3e6038c-cc59-41d5-ab5d-cb738dd5ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTransferLearning_op = create_component_from_func(modelTransferLearning,\n",
    "                                          base_image = BASE_IMAGE,\n",
    "                                          packages_to_install=[\"tensorflow\", \"matplotlib\", \"pathlib\", \"pandas\",\n",
    "                                                              \"numpy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bcded8d-b424-40d0-86d6-6e94f0817ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelTest(\n",
    "    data_path : InputPath(),\n",
    "    # x_test, y_test,\n",
    "    # model\n",
    "    model_path : OutputPath()\n",
    "):\n",
    "    import tensorflow as tf\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "    import numpy as np\n",
    "    \n",
    "    data_path = Path(data_path)\n",
    "    \n",
    "    \n",
    "    x_test = np.genfromtxt(data_path/\"x_test.csv\", delimiter=\",\", dtype=int)\n",
    "    y_test = np.genfromtxt(data_path/\"y_test.csv\", delimiter=\",\", dtype=int)\n",
    "    \n",
    "    model = tf.keras.models.load_model(data_path/\"myModel\")\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test)\n",
    "    # Visualization\n",
    "    y_pred = model.predict(x_test)\n",
    "    x_label = [x for x in range(0, x_test.shape[0])]\n",
    "    plt.scatter(x_label, y_test, label = \"Actual\", s = 0.01)\n",
    "    plt.scatter(x_label, y_pred, label = \"Predicted\", s = 0.01)\n",
    "    plt.xlabel('Sample count')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    output_path = Path(model_path)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    model.save(output_path/\"myModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ed076c1-e71b-4b4e-9dba-7f55864ebe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTest_op = create_component_from_func(modelTest,\n",
    "                                          base_image = BASE_IMAGE,\n",
    "                                          packages_to_install=[\"tensorflow\", \"matplotlib\", \"pathlib\", \"pandas\",\n",
    "                                                              \"numpy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a09727c8-e0cf-4136-a21e-2b38a265d06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelConvert(\n",
    "    model_path : InputPath(),\n",
    "    tflite_path : OutputPath()\n",
    "):\n",
    "    import tensorflow as tf\n",
    "    from pathlib import Path\n",
    "    import os\n",
    "    \n",
    "    model_path = Path(model_path)\n",
    "    \n",
    "    model = tf.keras.models.load_model(model_path/\"myModel\")\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    output_path = Path(tflite_path)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    file_path = output_path/\"myModel.tflite\"\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    print(\"success\")\n",
    "    # return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3baa464-ea17-4c87-8364-aae517543f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelConvert_op = create_component_from_func(modelConvert,\n",
    "                                          base_image = BASE_IMAGE,\n",
    "                                          packages_to_install=[\"tensorflow\", \"pathlib\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9065ce7-6de6-45b6-8983-dc6cd5295abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelServe(\n",
    "    input_path : InputPath()\n",
    "):\n",
    "    import minio\n",
    "    from pathlib import Path\n",
    "    minioClient = minio.Minio(\"minio-service.kubeflow:9000\",\n",
    "            access_key=\"minio\",\n",
    "            secret_key=\"minio123\",\n",
    "            secure=False\n",
    "        )\n",
    "    minio_path = \"M16M.tflite\"\n",
    "    local_path = Path(input_path)\n",
    "    minioClient.fput_object(bucket, minio_path, local_path/\"myModel.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ffc3db6-4910-4ca8-bc76-c5ff8f1af222",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelServe_op = create_component_from_func(ModelServe,\n",
    "                                           base_image = BASE_IMAGE,\n",
    "                                           packages_to_install = [\"minio\", \"pathlib\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08387cb8-139c-49b6-a4a6-bfb7fdfa3734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pod setting\n",
    "def pod_defaults(op):\n",
    "    op.set_memory_request('10Mi').set_cpu_request('10m')\n",
    "    # if you have to acess PVC,\n",
    "    # Use below annotated code.\n",
    "    volume_name = \"a305-storages\"\n",
    "    volume_mount_path = \"/mnt/data\"\n",
    "    volume = k8s.V1Volume(\n",
    "        name=volume_name,\n",
    "        persistent_volume_claim=k8s.V1PersistentVolumeClaimVolumeSource(claim_name=volume_name),\n",
    "    )\n",
    "    volume_mount = k8s.V1VolumeMount(\n",
    "        mount_path=volume_mount_path,\n",
    "        name=volume_name,\n",
    "    )\n",
    "    op.add_pvolumes({volume_mount_path: volume})\n",
    "    \n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17185b8d-faa4-4c60-adb3-c5d2b90543bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline using the component\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name = 'simple-test',\n",
    "    description = 'Toy Pipeline'\n",
    ")\n",
    "def simple_pipeline():\n",
    "    data_path = pod_defaults(getData_op())\n",
    "    data_path = data_path.output\n",
    "    \n",
    "    split_data_path = pod_defaults(dataSplit_op(data_path))\n",
    "    split_data_path = split_data_path.output\n",
    "    \n",
    "    model_path = pod_defaults(modelTransferLearning_op(split_data_path))\n",
    "    model_path = model_path.output\n",
    "    \n",
    "    test_path = pod_defaults(modelTest_op(model_path))\n",
    "    test_path = test_path.output\n",
    "    \n",
    "    serve_path = pod_defaults(modelConvert_op(test_path))\n",
    "    serve_path = serve_path.output\n",
    "    \n",
    "    pod_defaults(modelServe_op(serve_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1e7006b-455f-499c-9b05-b2799035ca11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/7ed5c17e-5146-4838-8b3f-7b4a7a3b8ab7\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/b9ee11da-15cc-46a0-8a7d-bc315809963a\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=b9ee11da-15cc-46a0-8a7d-bc315809963a)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments = {}\n",
    "EXPERIMENT_NAME = 'my_simple_pipeline'\n",
    "kfp.Client().create_run_from_pipeline_func(simple_pipeline,\n",
    "                                           arguments=arguments,\n",
    "                                           experiment_name=EXPERIMENT_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
